{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作业（三）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 独热编码和哑变量之间有什么区别？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "答：本质上差不多，哑变量常用于回归模型，one-hot在任何模型都可以用；\n",
    "哑变量为pandas的get_dummy方法，one-hot 在sklearn中引用（from sklearn.preprocessing import OneHotEncoder）；\n",
    "数据量大的话，哑变量太消耗资源，one-hot可以读数组，因此大规模数据集很方便。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 为什么要进⾏特征归⼀化？（简单描述即可）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "答：特征的单位或者大小相差较大，或者某特征的方差相比其他的特征要大出几个数量级，容易影响（支配）目标结果，使得一些算法无法学习到其它的特征， 需要用到一些方法进行无量纲化，使不同规格的数据转换到同一规格。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 填补缺失值的时候（中位数、众数、均值）三种填补⽅式的应⽤场景。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "答：中位数：数据比较离散时，如：在评估一个地区收入水平时，用中位数；\n",
    "众数:行为时间点等，如：“购物时间”；\n",
    "均值：商品推荐场景，如：“年收入”。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作业（四）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import 工具库\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import Imputer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据集\n",
    "df_train = pd.read_csv('./train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".以下对数据进行预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)# axis= 0 代表列\n",
    "\n",
    "df_train['Age'] = imp.fit_transform(df_train[['Age']].values) # Age空值处理,使用平均值\n",
    "\n",
    "df_train['Embarked'].fillna(\"S\",inplace=True) # Embarked空值处理，取众数“S”\n",
    "\n",
    "df_train.drop(['Cabin','PassengerId','Name','Ticket'],axis=1,inplace=True) # Cabin太多空值，删除该行;PassengerId\\Name\\Ticket为用户唯一标签，无用删除\n",
    "\n",
    "df_train['Sex'] = df_train['Sex'].map({\"male\":1,\"female\":0}) #性别按男：1 女：0替换标识\n",
    "\n",
    "df_train.loc[:,'family_size'] = df_train['SibSp']+df_train['Parch']+1 # 增多一列家庭成员列 1代表自己\n",
    "\n",
    "embarked = pd.get_dummies(df_train['Embarked'],prefix=\"embarked_\") # embarked做哑变量变化\n",
    "df_train = pd.concat([df_train,embarked],axis=1)\n",
    "\n",
    "df_train.drop(['SibSp','Parch','Embarked'],axis=1,inplace=True) # 删除已处理后不需要的列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".以下对数据进行标准化处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.iloc[:,1:]\n",
    "Y = np.array(df_train.iloc[:,0])\n",
    "\n",
    "X = X.as_matrix().astype(np.float) # 所有特征转化为np.float\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler #标准化库\n",
    "\n",
    "scaler = StandardScaler() #标准化\n",
    "\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".以下使用交叉验证，比较两个算法的准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN: 0.803584 (0.029128)\n",
      "-------------------------\n",
      "NB: 0.785607 (0.019851)\n",
      "-------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#调入工具包\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score,KFold\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 初始化模型\n",
    "models = []\n",
    "models.append(('KNN',KNeighborsClassifier()))\n",
    "models.append(('NB',GaussianNB()))\n",
    "\n",
    "# 初始化\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy' # 准确率\n",
    "for name, model in models:\n",
    "    kfold = KFold(5, shuffle=True, random_state = 0)\n",
    "    cv_results = cross_val_score(model, X, Y, cv=kfold)\n",
    "    results.append(cv_results) # 交叉验证给的结果分\n",
    "    names.append(name)\n",
    "    # 模型的标准差，体现模型的分值波动，std越小越稳定\n",
    "    msg = \"%s: %f (%f)\" %(name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "    print(\"-------------------------\")\n",
    "fig = plt.figure()\n",
    "fig.suptitle(\"Algorithm Comparison\")\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总结：就准确率比较来说，KNN要比NB数据表现要好。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
